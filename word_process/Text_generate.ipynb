{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.models import Sequential\n",
    "#from keras.utils.visualize_util import plot\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = open(\"alice_in_wonderland.txt\", 'rb')\n",
    "lines = []\n",
    "for line in fin:\n",
    "    line= line.strip().lower()\n",
    "    line = line.decode(\"ascii\",\"ignore\")\n",
    "    if len(line) == 0:\n",
    "        continue\n",
    "    lines.append(line)\n",
    "fin.close()\n",
    "text = \" \".join(lines)\n",
    "\n",
    "chars = set([c for c in text])\n",
    "nb_chars = len(chars)\n",
    "char2index = dict((c,i) for i,c in enumerate(chars))\n",
    "index2char = dict((i,c) for i, c in enumerate(chars))\n",
    "\n",
    "SEQLEN = 10\n",
    "STEP = 1\n",
    "input_chars = []\n",
    "label_chars = []\n",
    "for i in range(0, len(text) - SEQLEN, STEP):\n",
    "    input_chars.append(text[i:i+SEQLEN])\n",
    "    label_chars.append(text[i+SEQLEN])\n",
    "X= np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
    "y=np.zeros((len(input_chars),nb_chars),dtype = np.bool)\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "    y[i, char2index[label_chars[i]]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "NUM_ITERATIONS = 25\n",
    "NUM_EPOCH_PER_ITERATION = 1\n",
    "NUM_PREDS_PER_EPOCH = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(HIDDEN_SIZE, return_sequences = False,\n",
    "                   input_shape = (SEQLEN,nb_chars),\n",
    "                   unroll = True))\n",
    "model.add(Dense(nb_chars))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer = 'rmsprop')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Iteration #: 0\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 32s - loss: 2.3389    \n",
      "Generating from seed: ng silence\n",
      "ng silence the sout the ther sout the ther sout the ther sout the ther sout the ther sout the ther sout the th==================================================\n",
      "Iteration #: 1\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 33s - loss: 2.0470    \n",
      "Generating from seed: , the quee\n",
      ", the queen the gropling to she way har seat and the gropling to she way har seat and the gropling to she way ==================================================\n",
      "Iteration #: 2\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 33s - loss: 1.9436    \n",
      "Generating from seed: electronic\n",
      "electronice and the said the said the said the said the said the said the said the said the said the said the ==================================================\n",
      "Iteration #: 3\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 34s - loss: 1.8632    \n",
      "Generating from seed: iked them \n",
      "iked them it the gropent on the saided the saided the saided the saided the saided the saided the saided the s==================================================\n",
      "Iteration #: 4\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 34s - loss: 1.7978    \n",
      "Generating from seed:  very unco\n",
      " very uncors in a could be a cont in a could be a cont in a could be a cont in a could be a cont in a could be==================================================\n",
      "Iteration #: 5\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 33s - loss: 1.7446    \n",
      "Generating from seed: the trial \n",
      "the trial say said to the dont on the said to the dont on the said to the dont on the said to the dont on the ==================================================\n",
      "Iteration #: 6\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 33s - loss: 1.7001    \n",
      "Generating from seed: ere was no\n",
      "ere was not in a conting in a conting in a conting in a conting in a conting in a conting in a conting in a co==================================================\n",
      "Iteration #: 7\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 35s - loss: 1.6618    \n",
      "Generating from seed: orks, and \n",
      "orks, and the couse to said the doon a little she had alice the couse to said the doon a little she had alice ==================================================\n",
      "Iteration #: 8\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 35s - loss: 1.6303    \n",
      "Generating from seed: many small\n",
      "many small again, and was a little do and and the march hare the marks go and the was and all as all a little ==================================================\n",
      "Iteration #: 9\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 35s - loss: 1.6007    \n",
      "Generating from seed: oo, said a\n",
      "oo, said alice said the dormouse it the dormouse it the dormouse it the dormouse it the dormouse it the dormou==================================================\n",
      "Iteration #: 10\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 34s - loss: 1.5764    \n",
      "Generating from seed: he pleasur\n",
      "he pleasures the caterpillar had been that she was not into the was little she had berast was little she had b==================================================\n",
      "Iteration #: 11\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 37s - loss: 1.5541    \n",
      "Generating from seed:  trembling\n",
      " trembling very such a the had the hatter was the hatter was the hatter was the hatter was the hatter was the ==================================================\n",
      "Iteration #: 12\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 36s - loss: 1.5341    \n",
      "Generating from seed: -- i didnt\n",
      "-- i didnt the formon a little said the march hare in the more to the formon a little said the march hare in t==================================================\n",
      "Iteration #: 13\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 33s - loss: 1.5181    \n",
      "Generating from seed: out projec\n",
      "out project gutenberg-tm the door alice said alice said alice said alice said alice said alice said alice said==================================================\n",
      "Iteration #: 14\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 34s - loss: 1.5011    \n",
      "Generating from seed: d out a bo\n",
      "d out a bother to the king in a little sore soot come berast in the project gutenberg-tm electronic work in a ==================================================\n",
      "Iteration #: 15\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 41s - loss: 1.4869    \n",
      "Generating from seed: cked herse\n",
      "cked herself she was little shere the court the court the court the court the court the court the court the co==================================================\n",
      "Iteration #: 16\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 39s - loss: 1.4744    \n",
      "Generating from seed: onsider yo\n",
      "onsider you would be a little she had for the dormouse, and the hatter works and and got in a conting in a con==================================================\n",
      "Iteration #: 17\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 37s - loss: 1.4626    \n",
      "Generating from seed: words drin\n",
      "words drink on the same the first thing it to herself on the same the first thing it to herself on the same th==================================================\n",
      "Iteration #: 18\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 34s - loss: 1.4525    \n",
      "Generating from seed: is mouth c\n",
      "is mouth come of the cours of the some with a little before the stort, and well be the head to herself of the ==================================================\n",
      "Iteration #: 19\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 34s - loss: 1.4419    \n",
      "Generating from seed: hing like \n",
      "hing like alice had been and go do a little she was a little she was a little she was a little she was a littl==================================================\n",
      "Iteration #: 20\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 34s - loss: 1.4330    \n",
      "Generating from seed: r little t\n",
      "r little thing the caterpillar the was the caterpillar the was the caterpillar the was the caterpillar the was==================================================\n",
      "Iteration #: 21\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 34s - loss: 1.4237    \n",
      "Generating from seed: y slowly, \n",
      "y slowly, and she went on a conver and her from the expensing the executions to see it was a little she went o==================================================\n",
      "Iteration #: 22\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 34s - loss: 1.4159    \n",
      "Generating from seed: ack of car\n",
      "ack of care of the court, and the mock turtle was nothing to herself the dormouse of the words down and the pi==================================================\n",
      "Iteration #: 23\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 34s - loss: 1.4088    \n",
      "Generating from seed: h, music, \n",
      "h, music, said the mock turtle in the some of the some of the some of the some of the some of the some of the ==================================================\n",
      "Iteration #: 24\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 34s - loss: 1.4007    \n",
      "Generating from seed: ll! do as \n",
      "ll! do as she went on minute or two she went on minute or two she went on minute or two she went on minute or \n"
     ]
    }
   ],
   "source": [
    "for iteration in range(NUM_ITERATIONS):\n",
    "    print(\"=\"*50)\n",
    "    print(\"Iteration #: %d\" % (iteration))\n",
    "    model.fit(X,y,batch_size=BATCH_SIZE, epochs = NUM_EPOCH_PER_ITERATION)\n",
    "    \n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "    print(\"Generating from seed: %s\" % (test_chars))\n",
    "    print(test_chars, end=\"\")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "        Xtest = np.zeros((1,SEQLEN,nb_chars))\n",
    "        for i , ch in enumerate(test_chars):\n",
    "            Xtest[0,i, char2index[ch]] = 1\n",
    "        pred = model.predict(Xtest,verbose=0)[0]\n",
    "        ypred = index2char[np.argmax(pred)]\n",
    "        print(ypred, end=\"\")\n",
    "        # move forward with test_chars + ypred\n",
    "        test_chars = test_chars[1:] + ypred\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
